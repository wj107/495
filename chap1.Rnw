%----------495 Report, Chapter 1----------

%------------------------------------------------------------------------------------------------------------------------------------------------------
%---------------SECTION #1: INTRO, citation of GLM/NN in scholarly works, statistical software in pred. modelling------------------
%------------------------------------------------------------------------------------------------------------------------------------------------------

	\section{Intro to Predictive Analysis.}
		We live in the age of `Big Data'.  Using that data to measure, observe, and predict has great value:  economically, culturally, 
socially.  It's easy to say that this prediction is done by an app -- highlight data, point, click, ta-da!  You can find \href{https://www.google.com/maps/dir/Chicago,+Illinois/Champagne+Beach,+Vanuatu/@10.9584518,-169.5679877,3z/data=!4m13!4m12!1m5!1m1!1s0x880e2c3cd0f4cbed:0xafe0a6ad09c0c000!2m2!1d-87.6297982!2d41.8781136!1m5!1m1!1s0x6ef24c13ce5a7303:0x5807cbc94589a4bb!2m2!1d167.1203814!2d-15.1437919}{estimated travel time}, 
\href{https://www.amazon.com/Statistics-Dummies-Math-Science/dp/1119293529/ref=sr_1_1?ie=UTF8&qid=1518456852&sr=8-1&keywords=statistics+for+dummies+2017}{`Related materials' in consumer recommendations}, and \href{http://www.espn.com/mens-college-basketball/game?gameId=400986579}{predicted outcome of sporting events} with a few simple taps on your 
phone.  But what's the mathematical machinery behind these predictions?  Are all the predictions calculated in a similar manner?  How accurate is a
prediction?  How long would it take to compute a prediction, for a given set of data?  All of these questions are critical to ensure that predictive models 
remain practical and functional in our `Big Data' world.

Now, I will not discuss the specific predictive methods for proprietary applications, like the aforementioned travel predictions from Google or 
suggested product recommendations from Amazon.  But I will offer a cursory examination of two major mathematical methods for predictive analysis:
Generalized Linear Models (GLM), and Neural Networks (NN).  Both methods allow us to `train' mathematical models on an \textit{observed data set}, which can subsequently be used to predict future outcomes, or \textbf{response variables} .  Figure \#\ref{intromodels} contains two graphs that illustrate, graphically, these two types of mathematical models for a simple data set.

Given a sample of heights and weights from 20000 individuals in the United States collected from a 2015 survey conducted by the Centers for Disease
Control, the red lines indicate the predicted response variables from mathematical models trained on this data.  
		
		%intromodels
		\begin{figure}[h!]
		\centering
		\includegraphics[height=1.8in]{{model1.png}}
		\includegraphics[height=1.8in]{{model2.png}}
		\caption{Predictive models for height and weight data, trained using GLM methods (left), and NN methods (right)}
		\label{intromodels}
		\end{figure}
		%intromodels

These are simple examples; the data set has only two variables, and intuitively most people have an understanding of how these variables relate 
without appealing to mathematics.  But the underlying principle -- that the data can `train' a predictive mathematical model -- is one that we will
observe and analyze in many other contexts over the course of this paper.

%---------------SUBSECTION #1.1: GLM in scholarly works---------------------

	\subsection{GLM in Mathematical Literature.}
		For many scientific breakthroughs, there is no one, clear, defining `AHA!' moment where a new idea was discovered from scratch. For
GLM, however, the is a moment that approximates that: the publication in 1972, by Nelder and Wedderburn, of the paper `Generalized Linear Models'
in the \textit{Journal of the Royal Statistical Society}.  This often-cited work clearly laid out many of the ideas that are central to the study 
of GLMs today.  On the back of this work, and with the rise of widely-available statistical software to calculate GLM models such as R and SPSS, 
these models have been widely applied across the scientific literature in service of predictive analysis.  For instance, GLM has utility in
analyzing systems as varied as 
\href{https://www.sciencedirect.com/science/article/pii/S037877961630222X}{hydropower generation}, 
\href{https://www.sciencedirect.com/science/article/pii/S1470160X17306271}{habitat selection for small mammals}, and 
\href{https://www.sciencedirect.com/science/article/pii/S0167668715303358}{insurance claims}.  

Certainly, if GLM is used to obtain predictions of economically or ecologically important data, as suggested in the links above, we would want to 
ensure that the predictions are accurate. We will demonstrate in this paper how to estimate the standard error for a GLM model, which can be 
used to draw up confidence intervals and quantify the accuracy of a prediction.  Having these estimates for accuracy can be vital in determining
whether or not a predictive model is a valid basis for making policy decisions that carry great economic or environmental risk.

%---------------SUBSECTION #1.2: NN in scholarly works----------------------

	\subsection{NN in Mathematical Literature.}
		From the earliest work on \textit{threshold logic} by McCulloch and Pitts in 1943, to the explosion of machine learning algorithms
in use today in the age of `Big Data', the idea that the architecture of computing systems could be inspired by the architecture of the human brain
and its neural networks has maintained a presence in the scientific literature.  With the dramatic rise in computational power in the last 
generation along with statistical software such as R and SPSS, interest in neural networks has flourished, along with its place in scientific
research.  We can see examples of current research using neural nets to analyze topics as diverse as 
\href{https://www.sciencedirect.com/science/article/pii/S1877050918300656}{the gender of Russian authors},
\href{https://www.sciencedirect.com/science/article/pii/S2468203916300024}{the surface radiation in the Sundarban forest in India}, and 
\href{https://www.sciencedirect.com/science/article/pii/S1877050917303617}{routes through the city of Zhengzhou chosen by tourists}.
		
A distinct characteristic of neural nets is that of \textit{machine learning} -- given more data to `train' the model, it can improve the accuracy
of the response variable.  However, adding more data to a neural network requires more computational muscle, and for large or complex datasets,
it can require significantly more time to process.  So, similar to GLM, it will help us to have a means to check how accurate our predictions are,
so we can determine whether or not the added data and accuracy is worth the extra time needed for processing.

%---------------SUBSECTION #1.3: Accuracy of predictive models-----------

	\subsection{Use of Statistical Software in Predictive Models.}
		In dealing with `Big Data' and attempting to address complex, computationally-intensive problems (such as building a predictive model), the approaches have hinged on the technology available.  The twentieth century began with \href{https://ww2.amstat.org/about/statisticiansinhistory/index.cfm?fuseaction=paperinfo&PaperID=4}{punch card tabulating} but by the latter half of the century, statistical analysis had moved largely to computers.  Momentum for the trend of statistical software grew during the 1960s, and the release of SPSS in 1968 was a critical moment in making statistical analysis more widely available beyond actuarials and computer scientists.  [citation]  Similiarly, the SAS software and S programming language, released in 1976, helped to make statistical analysis accessible to a wide range of scientists.
Today, SPSS, SAS, and R (the modernized version of S) or similar software built in their mold are indispensable across the sciences and humanities for statistical analysis.  For example, [citations].

For the paper, all analysis was performed using R.  The preference for R, as opposed to SAS or SPSS, owes to the fact that it supports both the creation of both GLM and NN predictive models, its wide acceptance across industry, and it is freely available through the GNU General Public License.  Throughout this paper, excerpts of R code will appear as blocktext as seen below:

<<chunk2, echo=2, comment=NA, background="grey80">>=
greeting<-"Hello World!!"
print(greeting)
@

When snippets of R code appear within paragraphs, they will be formatted in the \texttt{Typewriter} font.
